{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESG Research \n",
    "### Yfinance, Pandas, NumPy\n",
    "\n",
    "\n",
    "# Installation\n",
    "* pip install pandas\n",
    "* pip install numpy\n",
    "* pip3 install tqdm\n",
    "* pip3 install seaborn\n",
    "* pip install yfinance | pip3 install yfinance\n",
    "* pip install git+https://github.com/rodrigobercini/yfinance.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "from pandas import Series, DataFrame\n",
    "from pandas.tseries import offsets\n",
    "import csv\n",
    "import datetime\n",
    "import csv\n",
    "from csv import writer\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "from yahoofinancials import YahooFinancials\n",
    "from sys import platform\n",
    "\n",
    "dt = datetime.datetime.today()\n",
    "\n",
    "YEAR = dt.year\n",
    "MONTH = dt.month\n",
    "CURRENT_CSV_FILE = bool\n",
    "\n",
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "       op_sys = \"linux\"\n",
    "elif platform == \"darwin\":\n",
    "       op_sys = \"Mac\"\n",
    "elif platform == \"win32\":\n",
    "       op_sys = \"Windows\"\n",
    "    \n",
    "ESG_COLUMNS = {'palmOil', 'controversialWeapons', 'gambling', 'socialScore', 'nuclear',\n",
    "       'furLeather', 'alcoholic', 'gmo', 'catholic', 'socialPercentile',\n",
    "       'peerCount', 'governanceScore', 'environmentPercentile',\n",
    "       'animalTesting', 'tobacco', 'totalEsg', 'highestControversy',\n",
    "       'esgPerformance', 'coal', 'pesticides', 'adult', 'percentile',\n",
    "       'peerGroup', 'smallArms', 'environmentScore', 'governancePercentile',\n",
    "       'militaryContract', \n",
    "       #'Stock'\n",
    "}\n",
    "\n",
    "ALL_COLUMNS = {'palmOil', 'peerCount', 'environmentScore', 'militaryContract',\n",
    "       'esgPerformance', 'coal', 'peerGroup', 'furLeather', 'gambling',\n",
    "       'animalTesting', 'catholic', 'nuclear', 'totalEsg', 'adult',\n",
    "       'environmentPercentile', 'highestControversy', 'socialScore',\n",
    "       'percentile', 'alcoholic', 'socialPercentile', 'pesticides',\n",
    "       'governancePercentile', 'controversialWeapons', 'gmo', 'smallArms',\n",
    "       'tobacco', 'governanceScore', 'Stock Ticker', 'Sector', 'Name'\n",
    "}\n",
    "\n",
    "\n",
    "USER_PATH = '/Users/MichaelCalmette/Documents/Finance Research/ESG Data Files/'\n",
    "DATE_PATH = \"esg-{}-{}.csv\".format(dt.month, dt.year)\n",
    "#DATE_PATH = \"esg-2-2022.csv\"\n",
    "\n",
    "FILE_PATH = os.path.join(USER_PATH,DATE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create functions to see if file exists / if there is data in there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function TextIOWrapper.close()>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(FILE_PATH, 'w')\n",
    "f.close\n",
    "### Check if DF is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_notification(title, t):\n",
    "    if op_sys == \"Mac\":\n",
    "        message = (\"Time taken: {} minutes\".format(t))\n",
    "        command = f'''\n",
    "        osascript -e 'display notification \"{message}\" with title \"{title}\"'\n",
    "        '''\n",
    "        os.system(command)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to compare data in esg-csv to all tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tickers.csv')\n",
    "#all_data = pd.DataFrame(columns=ESG_COLUMNS)\n",
    "# Only do if month is partially filled\n",
    "all_data = pd.read_csv(FILE_PATH)\n",
    "empty_stocks = pd.DataFrame(columns= ['Ticker'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJM\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-14</th>\n",
       "      <td>129.220001</td>\n",
       "      <td>130.910004</td>\n",
       "      <td>128.009995</td>\n",
       "      <td>128.929993</td>\n",
       "      <td>877000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-15</th>\n",
       "      <td>129.110001</td>\n",
       "      <td>129.490005</td>\n",
       "      <td>127.230003</td>\n",
       "      <td>129.300003</td>\n",
       "      <td>994600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-16</th>\n",
       "      <td>128.880005</td>\n",
       "      <td>129.360001</td>\n",
       "      <td>127.199997</td>\n",
       "      <td>129.339996</td>\n",
       "      <td>776200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-17</th>\n",
       "      <td>129.809998</td>\n",
       "      <td>130.600006</td>\n",
       "      <td>128.339996</td>\n",
       "      <td>129.580002</td>\n",
       "      <td>551900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-18</th>\n",
       "      <td>129.720001</td>\n",
       "      <td>129.720001</td>\n",
       "      <td>127.010002</td>\n",
       "      <td>128.070007</td>\n",
       "      <td>1423800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-21</th>\n",
       "      <td>128.630005</td>\n",
       "      <td>130.529999</td>\n",
       "      <td>128.630005</td>\n",
       "      <td>130.169998</td>\n",
       "      <td>792900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-22</th>\n",
       "      <td>130.529999</td>\n",
       "      <td>130.889999</td>\n",
       "      <td>128.750000</td>\n",
       "      <td>130.300003</td>\n",
       "      <td>737200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-23</th>\n",
       "      <td>131.190002</td>\n",
       "      <td>132.770004</td>\n",
       "      <td>130.160004</td>\n",
       "      <td>130.179993</td>\n",
       "      <td>826100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-24</th>\n",
       "      <td>130.220001</td>\n",
       "      <td>131.940002</td>\n",
       "      <td>130.220001</td>\n",
       "      <td>131.389999</td>\n",
       "      <td>503000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-25</th>\n",
       "      <td>131.589996</td>\n",
       "      <td>134.320007</td>\n",
       "      <td>131.080002</td>\n",
       "      <td>133.690002</td>\n",
       "      <td>1060500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-28</th>\n",
       "      <td>133.619995</td>\n",
       "      <td>134.360001</td>\n",
       "      <td>132.589996</td>\n",
       "      <td>133.940002</td>\n",
       "      <td>606500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-29</th>\n",
       "      <td>134.479996</td>\n",
       "      <td>135.600006</td>\n",
       "      <td>133.820007</td>\n",
       "      <td>135.429993</td>\n",
       "      <td>710800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-30</th>\n",
       "      <td>134.649994</td>\n",
       "      <td>134.899994</td>\n",
       "      <td>132.929993</td>\n",
       "      <td>134.880005</td>\n",
       "      <td>715200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-31</th>\n",
       "      <td>134.990005</td>\n",
       "      <td>136.139999</td>\n",
       "      <td>133.750000</td>\n",
       "      <td>135.410004</td>\n",
       "      <td>666000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-01</th>\n",
       "      <td>135.800003</td>\n",
       "      <td>137.589996</td>\n",
       "      <td>134.729996</td>\n",
       "      <td>137.509995</td>\n",
       "      <td>739300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-04</th>\n",
       "      <td>136.710007</td>\n",
       "      <td>136.740005</td>\n",
       "      <td>132.940002</td>\n",
       "      <td>134.639999</td>\n",
       "      <td>711000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-05</th>\n",
       "      <td>134.250000</td>\n",
       "      <td>137.789993</td>\n",
       "      <td>134.250000</td>\n",
       "      <td>137.770004</td>\n",
       "      <td>1134000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-06</th>\n",
       "      <td>138.169998</td>\n",
       "      <td>139.630005</td>\n",
       "      <td>136.250000</td>\n",
       "      <td>137.220001</td>\n",
       "      <td>1061700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-07</th>\n",
       "      <td>137.199997</td>\n",
       "      <td>137.970001</td>\n",
       "      <td>135.660004</td>\n",
       "      <td>137.339996</td>\n",
       "      <td>725200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-08</th>\n",
       "      <td>138.179993</td>\n",
       "      <td>139.410004</td>\n",
       "      <td>137.130005</td>\n",
       "      <td>138.800003</td>\n",
       "      <td>582100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-11</th>\n",
       "      <td>139.649994</td>\n",
       "      <td>140.559998</td>\n",
       "      <td>138.240005</td>\n",
       "      <td>139.429993</td>\n",
       "      <td>583400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-04-12</th>\n",
       "      <td>139.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>137.820007</td>\n",
       "      <td>139.410004</td>\n",
       "      <td>593600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open        High         Low       Close   Volume  \\\n",
       "Date                                                                  \n",
       "2022-03-14  129.220001  130.910004  128.009995  128.929993   877000   \n",
       "2022-03-15  129.110001  129.490005  127.230003  129.300003   994600   \n",
       "2022-03-16  128.880005  129.360001  127.199997  129.339996   776200   \n",
       "2022-03-17  129.809998  130.600006  128.339996  129.580002   551900   \n",
       "2022-03-18  129.720001  129.720001  127.010002  128.070007  1423800   \n",
       "2022-03-21  128.630005  130.529999  128.630005  130.169998   792900   \n",
       "2022-03-22  130.529999  130.889999  128.750000  130.300003   737200   \n",
       "2022-03-23  131.190002  132.770004  130.160004  130.179993   826100   \n",
       "2022-03-24  130.220001  131.940002  130.220001  131.389999   503000   \n",
       "2022-03-25  131.589996  134.320007  131.080002  133.690002  1060500   \n",
       "2022-03-28  133.619995  134.360001  132.589996  133.940002   606500   \n",
       "2022-03-29  134.479996  135.600006  133.820007  135.429993   710800   \n",
       "2022-03-30  134.649994  134.899994  132.929993  134.880005   715200   \n",
       "2022-03-31  134.990005  136.139999  133.750000  135.410004   666000   \n",
       "2022-04-01  135.800003  137.589996  134.729996  137.509995   739300   \n",
       "2022-04-04  136.710007  136.740005  132.940002  134.639999   711000   \n",
       "2022-04-05  134.250000  137.789993  134.250000  137.770004  1134000   \n",
       "2022-04-06  138.169998  139.630005  136.250000  137.220001  1061700   \n",
       "2022-04-07  137.199997  137.970001  135.660004  137.339996   725200   \n",
       "2022-04-08  138.179993  139.410004  137.130005  138.800003   582100   \n",
       "2022-04-11  139.649994  140.559998  138.240005  139.429993   583400   \n",
       "2022-04-12  139.000000  140.000000  137.820007  139.410004   593600   \n",
       "\n",
       "            Dividends  Stock Splits  \n",
       "Date                                 \n",
       "2022-03-14          0             0  \n",
       "2022-03-15          0             0  \n",
       "2022-03-16          0             0  \n",
       "2022-03-17          0             0  \n",
       "2022-03-18          0             0  \n",
       "2022-03-21          0             0  \n",
       "2022-03-22          0             0  \n",
       "2022-03-23          0             0  \n",
       "2022-03-24          0             0  \n",
       "2022-03-25          0             0  \n",
       "2022-03-28          0             0  \n",
       "2022-03-29          0             0  \n",
       "2022-03-30          0             0  \n",
       "2022-03-31          0             0  \n",
       "2022-04-01          0             0  \n",
       "2022-04-04          0             0  \n",
       "2022-04-05          0             0  \n",
       "2022-04-06          0             0  \n",
       "2022-04-07          0             0  \n",
       "2022-04-08          0             0  \n",
       "2022-04-11          0             0  \n",
       "2022-04-12          0             0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tic = df.sample(n=1)\n",
    "ticker_sym = tic.loc[tic.index[0],'Symbol'] # get ticker name ex: 'AAPL'\n",
    "print(ticker_sym)\n",
    "ticker = yf.Ticker(ticker_sym).history(period=\"1mo\")\n",
    "ticker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yahoo Financials to get additional stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yahoo_financials = YahooFinancials('AAPL')\n",
    "print(yahoo_financials.get_summary_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test pulling a random ticker and getting sustainability information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = df.sample(n=1)\n",
    "ticker_sym = tic.loc[tic.index[0],'Symbol'] # get ticker name ex: 'AAPL'\n",
    "ticker = yf.Ticker(ticker_sym)\n",
    "y = ticker.sustainability \n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [18:36<00:00, 11.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are: 66 stocks left in the database\n",
      "There are: 95 stocks with no ESG data\n",
      "Dataframe shape: 543\n",
      "Missing stocks: 357\n"
     ]
    }
   ],
   "source": [
    "df1_transposed = pd.DataFrame()\n",
    "no_data_stocks = 0\n",
    "start_time = time.time()\n",
    "temp = all_data[['Stock Ticker','Sector','Name']].copy()\n",
    "\n",
    "for x in tqdm(range(100)):\n",
    "    df_test = df.merge(temp, how = 'outer' ,indicator=True).loc[lambda x : x['_merge']=='left_only']\n",
    "    tic = df_test.sample(n=1)\n",
    "    ticker_sym = tic.loc[tic.index[0],'Symbol'] # get ticker name ex: 'AAPL'\n",
    "    ticker = yf.Ticker(ticker_sym)\n",
    "    y = ticker.sustainability \n",
    "    df1 = y\n",
    "\n",
    "    if df1 is None:\n",
    "        no_data_stocks += 1\n",
    "        empty_stocks = empty_stocks.append({\"Ticker\": ticker_sym}, ignore_index = True)\n",
    "    else:\n",
    "        df1_transposed = df1.transpose()\n",
    "        #print(df1_transposed.columns)\n",
    "        df1_transposed['Stock Ticker'] = ticker_sym\n",
    "        df1_transposed['Sector'] = tic.loc[tic.index[0],'Sector']\n",
    "        df1_transposed['Name'] = tic.loc[tic.index[0],'Name']\n",
    "\n",
    "        #all_data = df1_transposed\n",
    "        all_data = all_data.append(df1_transposed, ignore_index = True)\n",
    "    #temp = temp[temp['Stock Ticker'] != ticker_sym]\n",
    "\n",
    "all_shape = len(all_data)\n",
    "empty_shape = len(empty_stocks)\n",
    "time_taken = round((time.time() - start_time) / 60,2)\n",
    "\n",
    "print(\"There are: {} stocks left in the database\".format(len(df_test)))\n",
    "print(\"There are: {} stocks with no ESG data\".format(no_data_stocks))\n",
    "\n",
    "print(\"Dataframe shape: {}\".format(all_shape))\n",
    "print(\"Missing stocks: {}\".format(empty_shape))\n",
    "\n",
    "send_notification(\"Completed ESG Data Pull\",time_taken)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure there are no duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(543, 30)\n",
      "-100 duplicates have been dropped\n"
     ]
    }
   ],
   "source": [
    "s = len(all_data)\n",
    "print(all_data.shape)\n",
    "all_data = all_data.drop_duplicates()\n",
    "dropped=len(all_data) - s\n",
    "print(\"{} duplicates have been dropped\".format(dropped))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(443, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BR      1\n",
       "NEM     1\n",
       "MPC     1\n",
       "SBAC    1\n",
       "HAS     1\n",
       "       ..\n",
       "NFLX    1\n",
       "STT     1\n",
       "CCL     1\n",
       "EXPE    1\n",
       "KMI     1\n",
       "Name: Stock Ticker, Length: 443, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data['Stock Ticker'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESG File has column headers.\n",
      "ESG Data has been entered.\n"
     ]
    }
   ],
   "source": [
    "if os.stat(FILE_PATH).st_size == 0:\n",
    "    CURRENT_CSV_FILE = 0\n",
    "    print('ESG File is empty')\n",
    "    f = open(FILE_PATH, 'w')\n",
    "    f.close\n",
    "\n",
    "    with open(FILE_PATH, 'a', newline='') as f_object: \n",
    "        writer_object = writer(f_object) # Pass the CSV  file object to the writer() function\n",
    "        writer_object.writerow(all_data) # Pass the data in the list as an argument into the writerow() function\n",
    "        f_object.close()\n",
    "    print('Column names have been entered.')\n",
    "\n",
    "else:\n",
    "    CURRENT_CSV_FILE = 1\n",
    "    print('ESG File has column headers.')\n",
    "    all_data.to_csv(FILE_PATH, mode='a', index=False, header=False)\n",
    "    print('ESG Data has been entered.')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
